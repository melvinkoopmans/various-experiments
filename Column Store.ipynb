{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a CSV file with one column taken from a database. This column contains the type of an item, such as a document or news item. Lets take a look at a small sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 items in CSV.\n",
      "\n",
      "Sample of 10 items:\n",
      "\n",
      " ['agenda-item', 'news-item', 'vacancy', 'vacancy', 'vacancy', 'vacancy', 'news-item', 'vacancy', 'forum-topic', 'vacancy']\n"
     ]
    }
   ],
   "source": [
    "with open('itemtypes.csv', newline='') as csvfile:\n",
    "    data = [i[0] for i in list(csv.reader(csvfile))][1:]\n",
    "\n",
    "print(f'{len(data)} items in CSV.\\n\\nSample of 10 items:\\n\\n', data[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can encode all the different types in a dictionary so we can represent it by an integer instead of the full string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dictionaries(data):\n",
    "    encode_dictionary = { x: i for i, x in enumerate(set(data)) }\n",
    "    decode_dictionary = { i: x for i, x in enumerate(set(data)) }\n",
    "    \n",
    "    return encode_dictionary, decode_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'document': 0, 'vacancy': 1, 'bulletin-item': 2, 'expert-panel-question': 3, 'agenda-item': 4, 'page': 5, 'dossier': 6, 'generic-item': 7, 'forum-topic': 8, 'news-item': 9, 'venue': 10}\n",
      "{0: 'document', 1: 'vacancy', 2: 'bulletin-item', 3: 'expert-panel-question', 4: 'agenda-item', 5: 'page', 6: 'dossier', 7: 'generic-item', 8: 'forum-topic', 9: 'news-item', 10: 'venue'}\n"
     ]
    }
   ],
   "source": [
    "encode_dictionary, decode_dictionary = get_dictionaries(data)\n",
    "\n",
    "print(encode_dictionary)\n",
    "print(decode_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 9, 1, 1, 1, 1, 9, 1, 8, 1, 1, 9, 9, 1, 1, 1, 1, 8, 8, 0, 8, 9, 1, 9, 8, 9, 7, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 9, 1, 1, 1, 1, 9, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 2, 1, 1, 9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 10, 9, 9, 3, 1, 9, 0, 8, 9, 10, 1, 1, 1, 0, 8, 1, 9, 1, 0, 1, 1, 1, 1, 1, 9, 9, 1, 1, 1, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "encoded_data = [encode_dictionary.get(item) for item in data]\n",
    "print(encoded_data[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there are many repetitions of values, such as 8, 8, 8, 8. We can use _run-length encoding_ to save more space. We could encode 8, 8, 8, 8 as (8, 4), leaving us with just 2 integers: one for the actual value, and one for the run length. \n",
    "\n",
    "What if the rows are ordered such that there are no long runs of the same value? In case of a real database, where each row has multiple columns you'll have to find the most compact order. Computing the best ordering is an NP-hard problem. Most database systems therefore use a set of heuristics to give a good compaction but runs in a short amount of time.\n",
    "\n",
    "In this case, for demonstration purposes, we'll just use the existing array as it already has many repetitive item types and use run-length encoding. Lets take a look at the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_length_encode(data):\n",
    "    result = []\n",
    "    \n",
    "    count = 1\n",
    "    last_item = None\n",
    "    length = len(data)\n",
    "\n",
    "    for i, item in enumerate(data):    \n",
    "        if last_item is item:\n",
    "            count += 1\n",
    "            if i == (length - 1):\n",
    "                result.append((last_item, count))\n",
    "            \n",
    "        elif last_item != None:\n",
    "            result.append((last_item, count))\n",
    "            count = 1\n",
    "            \n",
    "        last_item = item\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(4, 1),\n",
       " (9, 1),\n",
       " (1, 4),\n",
       " (9, 1),\n",
       " (1, 1),\n",
       " (8, 1),\n",
       " (1, 2),\n",
       " (9, 2),\n",
       " (1, 4),\n",
       " (8, 2)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(run_length_encode(encoded_data)))\n",
    "run_length_encode(encoded_data)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We went from 500 items to just 11 items in the list!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe(data):\n",
    "    encode_dict, _ = get_dictionaries(data)\n",
    "    print('Encoding dictionary:\\n', encode_dict)\n",
    "\n",
    "    encoded_data = [encode_dict.get(item) for item in data]\n",
    "    print('\\nData:\\n', data[:5])\n",
    "    print('\\nDictionairy encoded:\\n', encoded_data[:5])\n",
    "    \n",
    "    full_encoded_data = run_length_encode(encoded_data)\n",
    "    print('\\nDictionairy + Run-length Encoded:\\n', full_encoded_data[:5])\n",
    "    \n",
    "    original_size = sys.getsizeof(pickle.dumps(data))\n",
    "    final_size = sys.getsizeof(pickle.dumps(full_encoded_data))\n",
    "\n",
    "    print(\n",
    "        f'\\nOriginal: {original_size}\\n' \\\n",
    "        f'Encoded: {sys.getsizeof(pickle.dumps(encoded_data))}\\n' \\\n",
    "        f'Dictionairy + Run-length Encoded: {final_size}\\n' \\\n",
    "        f'That is a {100 - (final_size * 100 // original_size)}% reduction in size.'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding dictionary:\n",
      " {'document': 0, 'vacancy': 1, 'bulletin-item': 2, 'expert-panel-question': 3, 'agenda-item': 4, 'page': 5, 'dossier': 6, 'generic-item': 7, 'forum-topic': 8, 'news-item': 9, 'venue': 10}\n",
      "\n",
      "Data:\n",
      " ['agenda-item', 'news-item', 'vacancy', 'vacancy', 'vacancy']\n",
      "\n",
      "Dictionairy encoded:\n",
      " [4, 9, 1, 1, 1]\n",
      "\n",
      "Dictionairy + Run-length Encoded:\n",
      " [(4, 1), (9, 1), (1, 4), (9, 1), (1, 1)]\n",
      "\n",
      "Original: 8429\n",
      "Encoded: 1041\n",
      "Dictionairy + Run-length Encoded: 2066\n",
      "That is a 76% reduction in size.\n"
     ]
    }
   ],
   "source": [
    "describe(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a 76% reduction in size! All this makes indexing a whole lot easier as well. When scanning all of the rows, you can just index into the lookup table.\n",
    "\n",
    "Notice how the dictionary + run-length encoding is actually longer. This is because there is not enough repetitiveness in the dataset to make this efficient. If we would sort the dataset we would get an even better compaction (however this is unrealistic when you have more than 1 column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding dictionary:\n",
      " {'forum-topic': 0, 'document': 1, 'bulletin-item': 2, 'vacancy': 3, 'agenda-item': 4, 'page': 5, 'dossier': 6, 'generic-item': 7, 'expert-panel-question': 8, 'news-item': 9, 'venue': 10}\n",
      "\n",
      "Data:\n",
      " ['agenda-item', 'agenda-item', 'agenda-item', 'agenda-item', 'agenda-item']\n",
      "\n",
      "Dictionairy encoded:\n",
      " [4, 4, 4, 4, 4]\n",
      "\n",
      "Dictionairy + Run-length Encoded:\n",
      " [(4, 35), (2, 2), (1, 101), (6, 3), (8, 1)]\n",
      "\n",
      "Original: 8429\n",
      "Encoded: 1041\n",
      "Dictionairy + Run-length Encoded: 118\n",
      "That is a 99% reduction in size.\n"
     ]
    }
   ],
   "source": [
    "describe(sorted(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
