{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_data = [\n",
    "    'NL', 'BE', 'US', 'US', 'AF', 'GE', 'US', 'PO',\n",
    "    'FN', 'LT', 'RU', 'NL', 'DE', 'DA', 'ZW', 'AF'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_data = [\n",
    "    'NL', 'NL', 'NL', 'US', 'US', 'NL', 'NL', 'NL',\n",
    "    'BE', 'BE', 'NL', 'NL', 'BE', 'US', 'US', 'US'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is 150 MB for every 1 GB. That is 150 GB for every 1 TB. That is 150 TB for every 1 PB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dictionaries(data):\n",
    "    encode_dictionary = { x: i for i, x in enumerate(set(data)) }\n",
    "    decode_dictionary = { i: x for i, x in enumerate(set(data)) }\n",
    "    \n",
    "    return encode_dictionary, decode_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BE': 0, 'US': 1, 'NL': 2}\n",
      "{0: 'BE', 1: 'US', 2: 'NL'}\n"
     ]
    }
   ],
   "source": [
    "lc_encode_dictionary, lc_decode_dictionary = get_dictionaries(lc_data)\n",
    "\n",
    "print(lc_encode_dictionary)\n",
    "print(lc_decode_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 1, 1, 2, 2, 2, 0, 0, 2, 2, 0, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "lc_encoded_data = [lc_encode_dictionary.get(item) for item in lc_data]\n",
    "print(lc_encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_length_encode(data):\n",
    "    result = []\n",
    "    \n",
    "    count = 1\n",
    "    last_item = None\n",
    "    length = len(data)\n",
    "\n",
    "    for i, item in enumerate(data):    \n",
    "        if last_item is item:\n",
    "            count += 1\n",
    "            if i == (length - 1):\n",
    "                result.append((last_item, count))\n",
    "            \n",
    "        elif last_item != None:\n",
    "            result.append((last_item, count))\n",
    "            count = 1\n",
    "            \n",
    "        last_item = item\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 3), (1, 2), (2, 3), (0, 2), (2, 2), (0, 1), (1, 3)]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_length_encode(lc_encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe(data):\n",
    "    encode_dict, _ = get_dictionaries(data)\n",
    "    print('Encoding dictionary:\\n', encode_dict)\n",
    "\n",
    "    encoded_data = [encode_dict.get(item) for item in data]\n",
    "    print('\\nData:\\n', data)\n",
    "    print('\\nDictionairy encoded:\\n', encoded_data)\n",
    "\n",
    "    sorted_encoded_data = sorted(encoded_data)\n",
    "    print('\\nSorted encoded data:\\n', sorted_encoded_data)\n",
    "    \n",
    "    full_encoded_data = run_length_encode(sorted_encoded_data)\n",
    "    print('\\nDictionairy + Run-length Encoded:\\n', full_encoded_data)\n",
    "    \n",
    "    original_size = sys.getsizeof(pickle.dumps(data))\n",
    "    final_size = sys.getsizeof(pickle.dumps(full_encoded_data))\n",
    "\n",
    "    print(\n",
    "        f'\\nOriginal: {original_size}\\n' \\\n",
    "        f'Encoded: {sys.getsizeof(pickle.dumps(encoded_data))}\\n' \\\n",
    "        f'Encoded: {final_size}\\n' \\\n",
    "        f'That is a {100 - (final_size * 100 // original_size)}% reduction.'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-Cardinality\n",
      "--------------\n",
      "\n",
      "Encoding dictionary:\n",
      " {'BE': 0, 'US': 1, 'NL': 2}\n",
      "\n",
      "Data:\n",
      " ['NL', 'NL', 'NL', 'US', 'US', 'NL', 'NL', 'NL', 'BE', 'BE', 'NL', 'NL', 'BE', 'US', 'US', 'US']\n",
      "\n",
      "Dictionairy encoded:\n",
      " [2, 2, 2, 1, 1, 2, 2, 2, 0, 0, 2, 2, 0, 1, 1, 1]\n",
      "\n",
      "Sorted encoded data:\n",
      " [0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "\n",
      "Dictionairy + Run-length Encoded:\n",
      " [(0, 3), (1, 5), (2, 8)]\n",
      "\n",
      "Original: 94\n",
      "Encoded: 73\n",
      "Encoded: 62\n",
      "That is a 35% reduction.\n"
     ]
    }
   ],
   "source": [
    "print('Low-Cardinality\\n--------------\\n')\n",
    "describe(lc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-Cardinality\n",
      "--------------\n",
      "\n",
      "Encoding dictionary:\n",
      " {'DE': 0, 'PO': 1, 'US': 2, 'BE': 3, 'GE': 4, 'ZW': 5, 'LT': 6, 'RU': 7, 'AF': 8, 'DA': 9, 'NL': 10, 'FN': 11}\n",
      "\n",
      "Data:\n",
      " ['NL', 'BE', 'US', 'US', 'AF', 'GE', 'US', 'PO', 'FN', 'LT', 'RU', 'NL', 'DE', 'DA', 'ZW', 'AF']\n",
      "\n",
      "Dictionairy encoded:\n",
      " [10, 3, 2, 2, 8, 4, 2, 1, 11, 6, 7, 10, 0, 9, 5, 8]\n",
      "\n",
      "Sorted encoded data:\n",
      " [0, 1, 2, 2, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10, 10, 11]\n",
      "\n",
      "Dictionairy + Run-length Encoded:\n",
      " [(0, 1), (1, 1), (2, 3), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 2), (9, 1), (10, 2)]\n",
      "\n",
      "Original: 157\n",
      "Encoded: 73\n",
      "Encoded: 118\n",
      "That is a 25% reduction.\n"
     ]
    }
   ],
   "source": [
    "print('High-Cardinality\\n--------------\\n')\n",
    "describe(hc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
